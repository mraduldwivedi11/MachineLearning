{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from pprint import pprint\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching 20 news group data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset=\"train\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check most occured 2000 words\n",
    "\n",
    "dictionary={}\n",
    "\n",
    "shortword = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "\n",
    "for i in range(0,len(twenty_train['data'])):  # to traverse from all doc\n",
    "    strn=re.sub(r'[^\\w\\s]','',twenty_train['data'][i])  #regular expressions to remove punctuation words and digit words\n",
    "    strn=re.sub(r'\\w*\\d\\w*', '', strn).strip()\n",
    "    shortword.sub('', strn)\n",
    "    word_tokens = strn.split(\" \")                 # split whole text into space separted words\n",
    "    word_tokens = [word.lower() for word in word_tokens] # convert it into lower cases\n",
    "    for w in word_tokens:\n",
    "        if w.isalpha():                                   # to check if that word is alphanumeric\n",
    "            if w not in stop_word:\n",
    "                if len(w)>2:\n",
    "                    if w in dictionary:                   # to chech if it is already in dic so increment its occurenc\n",
    "                        dictionary[w]=dictionary[w]+1\n",
    "                    else:\n",
    "                        dictionary[w]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to sort that words according to occurance\n",
    "features = sorted(dictionary.items(), key=operator.itemgetter(1),reverse=True)[0:2000] # and do slicing for 2000 word\n",
    "features_list=[]\n",
    "for i in features:\n",
    "    features_list.append(i[0])   ## append every feature tuple's 0'th element into feature list\n",
    "#pprint(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(0, index=range(0,len(twenty_train['data'])), columns=range(0,2000))\n",
    "                            ## create a empty dataframe initialize from 0 of shape (11314, 2000) \n",
    "                            \n",
    "    \n",
    "## in below loop we traverse from all doc and convert it into words and put our selected word features in new row for \n",
    "# every new doc\n",
    "    \n",
    "for i in range(0,len(twenty_train['data'])):\n",
    "        word_tokens = twenty_train['data'][i].split(\" \")  ## convert one doc into words\n",
    "        word_tokens = [word.lower() for word in word_tokens]\n",
    "        for word in word_tokens:\n",
    "            if word in features_list:                         # check if that word is in our feature words\n",
    "                column_no=features_list.index(word)\n",
    "                df.iloc[i,column_no]=df.iloc[i,column_no]+1   # increments it's occurance by one\n",
    "            else:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(twenty_train['target']))\n",
    "# print(df.shape)\n",
    "# twenty_train['target'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert our dataframe into numpy\n",
    "x=df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLabelled(column):\n",
    "    second_limit = column.mean()\n",
    "    first_limit = 0.5 * second_limit\n",
    "    third_limit = 1.5*second_limit\n",
    "    for i in range (0,len(column)):\n",
    "        if (column[i] < first_limit):\n",
    "            column[i] = 0\n",
    "        elif (column[i] < second_limit):\n",
    "            column[i] = 1\n",
    "        elif(column[i] < third_limit):\n",
    "            column[i] = 2\n",
    "        else:\n",
    "            column[i] = 3\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,x.shape[-1]):\n",
    "    x[:,i] = makeLabelled(x[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(x,twenty_train['target'],test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train our classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "rec.motorcycles\n"
     ]
    }
   ],
   "source": [
    "single_predict=clf.predict(X_test[52].reshape(1, -1))\n",
    "print(type(single_predict))\n",
    "print(twenty_train['target_names'][single_predict[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# print(classification_report(Y_test,Y_pred))\n",
    "# print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary_of_dataframe(X_train, Y_train):\n",
    "    result = {}\n",
    "    class_values = set(Y_train)\n",
    "    for current_class in class_values:\n",
    "        result[current_class] = {}\n",
    "        result[\"total_data\"] = len(Y_train)\n",
    "        current_class_rows = (Y_train == current_class)\n",
    "        X_train_current = X_train[current_class_rows]\n",
    "        Y_train_current = Y_train[current_class_rows]\n",
    "        num_features = X_train.shape[1]\n",
    "        result[current_class][\"total_count\"] = len(Y_train_current)\n",
    "        for j in range(1, num_features + 1):\n",
    "            result[current_class][j] = {}\n",
    "            all_possible_values = set(X_train[:, j - 1])\n",
    "            for current_value in all_possible_values:\n",
    "                result[current_class][j][current_value] = (X_train_current[:, j - 1] == current_value).sum()\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dictionary=create_dictionary_of_dataframe(X_train , Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 3])\n"
     ]
    }
   ],
   "source": [
    "pprint(df_dictionary[0][3].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(df_dictionary, x, current_class):\n",
    "    output = np.log(df_dictionary[current_class][\"total_count\"]) - np.log(df_dictionary[\"total_data\"])\n",
    "    num_features = len(df_dictionary[current_class].keys()) - 1;\n",
    "    for j in range(1, num_features + 1):\n",
    "        xj = x[j - 1]\n",
    "#          print(j,end=(\",\"))\n",
    "#         print(current_class,j,xj)\n",
    "        count_current_class_with_value_xj = df_dictionary[current_class][j][xj] + 1\n",
    "        count_current_class = df_dictionary[current_class][\"total_count\"] + len(df_dictionary[current_class][j].keys())\n",
    "        current_xj_probablity = np.log(count_current_class_with_value_xj) - np.log(count_current_class)\n",
    "        output = output + current_xj_probablity\n",
    "#     print()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSinglePoint(df_dictionary, x):\n",
    "    classes = df_dictionary.keys()\n",
    "    best_p = -1000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    for current_class in classes:\n",
    "        if (current_class == \"total_data\"):\n",
    "            continue\n",
    "        p_current_class = probability(df_dictionary, x, current_class)\n",
    "        \n",
    "        if (first_run or p_current_class > best_p):\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "        #print(twenty_train['target_names'][best_class])\n",
    "#         print(best_class)\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df_dictionary, X_test):\n",
    "    y_pred = []\n",
    "#     i=0\n",
    "    for x in X_test:\n",
    "        x_class = predictSinglePoint(df_dictionary, x)\n",
    "        y_pred.append(x_class)\n",
    "#         print(i,end=\",\")\n",
    "#         i=i+1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2829, 2000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 12, 4, 14, 10, 9, 11, 7, 14, 11, 10, 9, 3, 1, 6, 9, 6, 14, 6, 5, 6, 4, 10, 6, 13, 4, 14, 6, 6, 3, 2, 18, 6, 1, 11, 15, 3, 2, 16, 6, 6, 6, 16, 16, 18, 4, 14, 6, 17, 14, 13, 3, 8, 13, 4, 0, 10, 14, 6, 4, 10, 6, 19, 10, 8, 1, 19, 4, 1, 1, 6, 7, 16, 12, 4, 2, 18, 4, 1, 6, 6, 12, 10, 9, 4, 4, 2, 8, 6, 4, 16, 9, 6, 7, 3, 6, 1, 6, 6, 18, 6, 16, 3, 15, 12, 15, 7, 0, 3, 9, 10, 16, 2, 1, 2, 6, 12, 4, 8, 0, 1, 12, 3, 0, 6, 3, 5, 14, 9, 6, 6, 1, 5, 1, 6, 3, 14, 3, 15, 1, 3, 10, 6, 5, 12, 17, 6, 6, 2, 6, 6, 8, 8, 1, 9, 8, 1, 1, 12, 1, 2, 13, 4, 2, 8, 17, 4, 4, 6, 8, 7, 8, 10, 6, 6, 5, 13, 6, 4, 5, 5, 11, 6, 9, 4, 5, 1, 18, 6, 18, 2, 14, 8, 9, 13, 6, 5, 16, 6, 8, 2, 5, 16, 14, 3, 1, 14, 19, 3, 6, 10, 6, 3, 14, 8, 3, 12, 12, 4, 9, 3, 9, 1, 5, 9, 17, 6, 14, 4, 6, 8, 15, 3, 6, 5, 15, 1, 18, 6, 18, 8, 11, 10, 4, 9, 15, 1, 17, 18, 19, 17, 9, 6, 9, 5, 15, 6, 13, 6, 7, 16, 6, 0, 4, 6, 6, 0, 6, 3, 8, 1, 6, 0, 8, 11, 12, 19, 1, 6, 8, 8, 2, 1, 12, 6, 6, 7, 11, 8, 12, 4, 4, 1, 16, 10, 6, 13, 1, 18, 6, 6, 17, 4, 14, 4, 13, 11, 6, 6, 2, 7, 6, 4, 6, 1, 14, 8, 11, 13, 3, 16, 3, 14, 14, 2, 10, 9, 6, 9, 2, 6, 2, 1, 6, 5, 4, 19, 15, 9, 15, 6, 16, 15, 17, 15, 0, 5, 9, 9, 18, 0, 16, 14, 15, 6, 12, 6, 12, 16, 1, 6, 7, 17, 18, 15, 5, 8, 18, 6, 6, 16, 15, 13, 6, 4, 11, 15, 15, 14, 15, 7, 1, 19, 3, 13, 7, 2, 15, 6, 6, 15, 10, 5, 14, 1, 0, 2, 17, 16, 2, 3, 5, 13, 3, 16, 6, 15, 6, 2, 9, 6, 15, 15, 12, 6, 15, 13, 7, 3, 8, 13, 3, 12, 14, 6, 6, 2, 17, 12, 8, 3, 15, 11, 19, 7, 0, 0, 3, 9, 5, 14, 6, 6, 6, 10, 6, 4, 11, 6, 16, 1, 10, 8, 10, 1, 13, 14, 11, 11, 2, 18, 11, 10, 10, 6, 11, 11, 10, 18, 6, 6, 18, 15, 15, 10, 11, 2, 11, 16, 0, 12, 17, 16, 12, 17, 0, 6, 7, 13, 19, 6, 4, 9, 6, 6, 1, 17, 6, 13, 10, 1, 1, 15, 17, 6, 16, 0, 19, 3, 3, 15, 15, 7, 14, 11, 2, 6, 19, 8, 6, 3, 8, 6, 6, 7, 16, 17, 6, 10, 6, 15, 4, 1, 12, 13, 10, 17, 8, 9, 11, 1, 8, 8, 6, 13, 0, 1, 4, 16, 7, 15, 6, 2, 5, 3, 6, 18, 2, 6, 1, 6, 1, 12, 3, 10, 1, 8, 8, 10, 11, 3, 6, 8, 17, 3, 9, 16, 8, 8, 15, 8, 6, 4, 8, 0, 6, 13, 2, 6, 4, 19, 6, 10, 1, 1, 2, 11, 4, 6, 4, 12, 10, 4, 6, 6, 7, 15, 2, 3, 5, 12, 8, 8, 17, 11, 3, 7, 12, 6, 17, 12, 13, 17, 10, 1, 16, 19, 12, 6, 10, 15, 10, 11, 8, 6, 6, 2, 1, 13, 6, 17, 7, 2, 9, 12, 11, 18, 13, 11, 1, 18, 1, 6, 12, 10, 10, 2, 19, 18, 8, 14, 6, 7, 1, 3, 4, 1, 10, 11, 14, 4, 11, 18, 9, 17, 4, 1, 12, 19, 4, 8, 10, 14, 1, 4, 1, 18, 6, 5, 12, 6, 10, 6, 1, 8, 8, 4, 6, 13, 6, 1, 1, 15, 8, 1, 6, 6, 8, 14, 16, 6, 7, 1, 3, 6, 6, 6, 8, 10, 6, 13, 6, 9, 16, 6, 15, 13, 11, 3, 8, 9, 0, 2, 13, 2, 19, 6, 7, 0, 3, 3, 4, 3, 0, 13, 6, 6, 5, 15, 6, 6, 10, 6, 10, 14, 17, 6, 18, 10, 3, 2, 9, 8, 0, 6, 15, 16, 6, 3, 6, 12, 6, 6, 6, 2, 9, 15, 14, 7, 4, 13, 12, 13, 1, 6, 4, 5, 13, 6, 11, 6, 8, 11, 1, 10, 8, 1, 9, 4, 2, 4, 12, 3, 9, 14, 6, 6, 18, 16, 1, 1, 6, 16, 5, 11, 12, 12, 11, 15, 6, 11, 0, 6, 1, 1, 9, 3, 2, 11, 2, 15, 3, 7, 17, 2, 16, 11, 11, 6, 4, 6, 2, 19, 6, 1, 6, 15, 9, 17, 5, 1, 6, 3, 6, 16, 6, 18, 4, 16, 6, 15, 6, 8, 9, 6, 6, 10, 1, 18, 19, 6, 5, 17, 19, 15, 14, 1, 8, 2, 6, 17, 6, 8, 15, 14, 1, 6, 8, 6, 6, 17, 4, 3, 19, 8, 19, 17, 3, 17, 9, 15, 5, 6, 1, 2, 10, 16, 12, 8, 9, 8, 3, 14, 8, 1, 8, 9, 4, 15, 9, 9, 8, 16, 17, 2, 12, 10, 8, 10, 6, 5, 16, 15, 8, 10, 6, 12, 17, 6, 1, 11, 6, 18, 6, 6, 9, 4, 10, 2, 5, 6, 3, 4, 2, 8, 1, 6, 18, 2, 2, 19, 19, 15, 5, 7, 3, 6, 9, 6, 2, 10, 7, 19, 3, 0, 17, 1, 6, 17, 16, 1, 18, 4, 5, 9, 6, 12, 3, 9, 17, 13, 6, 6, 2, 3, 13, 9, 13, 4, 11]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_self = predict(df_dictionary,X_test[0:1000,:])\n",
    "print(y_pred_self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 12, 13, 14,  9,  9, 11,  8, 14, 11, 10,  9,  4,  9,  0,  9, 13,\n",
       "       14,  7,  5,  9,  4, 10,  6, 13,  4, 14,  5,  6,  6,  2, 18,  1,  1,\n",
       "       11, 15,  4,  2, 16, 12])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.52      0.59        31\n",
      "          1       0.39      0.56      0.46        54\n",
      "          2       0.62      0.63      0.63        49\n",
      "          3       0.75      0.58      0.66        74\n",
      "          4       0.65      0.64      0.64        58\n",
      "          5       0.75      0.44      0.55        55\n",
      "          6       0.20      0.88      0.33        43\n",
      "          7       0.74      0.43      0.54        47\n",
      "          8       0.59      0.72      0.65        53\n",
      "          9       0.77      0.68      0.72        53\n",
      "         10       0.90      0.85      0.87        52\n",
      "         11       0.88      0.73      0.80        48\n",
      "         12       0.60      0.46      0.52        52\n",
      "         13       0.80      0.55      0.65        51\n",
      "         14       0.94      0.57      0.71        58\n",
      "         15       0.88      0.71      0.79        62\n",
      "         16       0.87      0.73      0.80        45\n",
      "         17       0.92      0.62      0.74        53\n",
      "         18       0.62      0.55      0.58        33\n",
      "         19       0.58      0.48      0.53        29\n",
      "\n",
      "avg / total       0.72      0.62      0.65      1000\n",
      "\n",
      "[[16  2  0  0  2  0  6  0  1  0  0  0  1  0  0  1  0  0  0  2]\n",
      " [ 0 30  3  0  0  3 12  0  1  0  0  2  0  1  1  0  0  0  1  0]\n",
      " [ 0  2 31  4  1  1 10  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  7  1 43  4  1 18  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  5 37  0 11  0  0  0  0  1  2  1  0  0  0  0  0  0]\n",
      " [ 0 13  6  1  2 24  8  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  2  0  0 38  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  3  0 16 20  4  0  0  0  1  0  0  0  1  0  1  0]\n",
      " [ 0  2  1  0  1  1  5  4 38  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  1  0  0  1  0  8  0  1 36  4  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  4  0  0  4 44  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  1  0  0  1  1  0  1  0  0 35  5  0  0  0  1  1  0  0]\n",
      " [ 0  6  1  1  2  0 14  0  1  0  1  0 24  1  0  0  1  0  0  0]\n",
      " [ 0  3  4  0  1  0  6  0  2  3  0  0  1 28  0  2  0  0  1  0]\n",
      " [ 1  3  0  0  2  0  9  1  6  0  0  0  1  1 33  0  0  1  0  0]\n",
      " [ 2  2  1  0  0  0  5  0  1  0  0  0  3  1  0 44  0  1  1  1]\n",
      " [ 0  2  0  0  0  0  3  1  2  0  0  0  0  0  0  0 33  0  2  2]\n",
      " [ 1  0  0  0  0  1  8  1  0  4  0  0  1  0  0  0  0 33  3  1]\n",
      " [ 1  0  0  0  1  0  4  0  2  0  0  0  0  1  1  0  1  0 18  4]\n",
      " [ 2  0  0  0  0  0  4  0  4  0  0  0  1  1  0  3  0  0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(Y_test[0:1000],y_pred_self))\n",
    "print(confusion_matrix(Y_test[0:1000],y_pred_self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_self = predict(df_dictionary,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_self = predict(df_dictionary,X_test)\n",
    "classes = df_dictionary.keys()\n",
    "classes\n",
    "len(X_test[0])\n",
    "df_dictionary[\"total_data\"]\n",
    "len(df_dictionary[0].keys())\n",
    "x[0][0]\n",
    "\n",
    "pprint(df_dictionary[0][1669])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
